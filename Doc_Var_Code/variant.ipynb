{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.typo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功保存修改后的JSON文件: D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_1.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "\n",
    "def modify_letters_with_probability(text, probability=0.001):\n",
    "\n",
    "    modified_text = []\n",
    "    for char in text:\n",
    "        if char.isalpha():\n",
    "            if random.random() < probability:\n",
    "                if char.islower():\n",
    "                    replacement = random.choice(string.ascii_lowercase)\n",
    "                else:\n",
    "                    replacement = random.choice(string.ascii_uppercase)\n",
    "                modified_text.append(replacement)\n",
    "            else:\n",
    "                modified_text.append(char)\n",
    "        else:\n",
    "            modified_text.append(char)\n",
    "    return ''.join(modified_text)\n",
    "def process_json_file(input_json_path, output_json_path, probability=0.001):\n",
    "\n",
    "    try:\n",
    "        with open(input_json_path, 'r', encoding='utf-8') as infile:\n",
    "            data = json.load(infile)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to read the JSON file {input_json_path}: {e}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, str):\n",
    "            modified_value = modify_letters_with_probability(value, probability)\n",
    "            data[key] = modified_value\n",
    "        else:\n",
    "            print(f\"key {key} value is not a string, skip the modification.\")\n",
    "\n",
    "    try:\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as outfile:\n",
    "            json.dump(data, outfile, ensure_ascii=False, indent=4)\n",
    "        print(f\"The modified JSON file is saved: {output_json_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"unable to save JSON file {output_json_path}: {e}\")\n",
    "\n",
    "input_json_path = r\"D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn.json\"\n",
    "output_json_path = r\"D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_1.json\"\n",
    "process_json_file(input_json_path, output_json_path, probability=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.captial all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将 D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_1.json 中所有字母转换为大写并保存为 D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_12.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def convert_values_to_uppercase(data):\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "        return {k: convert_values_to_uppercase(v) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [convert_values_to_uppercase(item) for item in data]\n",
    "    elif isinstance(data, str):\n",
    "        return data.upper()\n",
    "    else:\n",
    "        \n",
    "        return data\n",
    "\n",
    "def convert_json_file_to_uppercase(input_json_path, output_json_path):\n",
    "    \n",
    "    \n",
    "    with open(input_json_path, 'r', encoding='utf-8') as infile:\n",
    "        data = json.load(infile)\n",
    "    \n",
    "    \n",
    "    modified_data = convert_values_to_uppercase(data)\n",
    "\n",
    "    \n",
    "    with open(output_json_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(modified_data, outfile, ensure_ascii=False, indent=4)\n",
    "    print(f\"All letters in {input_json_path} have been capitalized and saved as {output_json_path}\")\n",
    "\n",
    "input_file = r\"D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_1.json\"\n",
    "output_file = r\"D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_12.json\"\n",
    "convert_json_file_to_uppercase(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.random no space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功保存修改后的JSON文件: D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_123.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "def delete_spaces_with_probability(text, probability=0.001):\n",
    "   \n",
    "    modified_text = []\n",
    "    for char in text:\n",
    "        if char == ' ':\n",
    "            if random.random() < probability:\n",
    "                continue\n",
    "        modified_text.append(char)\n",
    "    return ''.join(modified_text)\n",
    "\n",
    "def process_data(data, probability=0.001):\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "        return {k: process_data(v, probability) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [process_data(element, probability) for element in data]\n",
    "    elif isinstance(data, str):\n",
    "        return delete_spaces_with_probability(data, probability)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def modify_json_spaces(input_json_path, output_json_path, probability=0.001):\n",
    "\n",
    "    try:\n",
    "        with open(input_json_path, 'r', encoding='utf-8') as infile:\n",
    "            data = json.load(infile)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to read the JSON file {input_json_path}: {e}\")\n",
    "        return\n",
    "    \n",
    "    modified_data = process_data(data, probability)\n",
    "    \n",
    "    try:\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as outfile:\n",
    "            json.dump(modified_data, outfile, ensure_ascii=False, indent=4)\n",
    "        print(f\"The modified JSON file has been saved successfully: {output_json_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to save JSON file {output_json_path}: {e}\")\n",
    "\n",
    "\n",
    "input_file = r\"D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_12.json\" \n",
    "output_file = r\"D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_123.json\"\n",
    "modify_json_spaces(input_file, output_file, probability=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.no punctation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功保存修改后的JSON文件: D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_1234.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(rf\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "\n",
    "def process_data(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {k: process_data(v) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [process_data(element) for element in data]\n",
    "    elif isinstance(data, str):\n",
    "        return remove_punctuation(data)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def delete_punctuation_from_json(input_json_path, output_json_path):\n",
    "\n",
    "    try:\n",
    "        with open(input_json_path, 'r', encoding='utf-8') as infile:\n",
    "            data = json.load(infile)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to read the JSON file {input_json_path}: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 处理数据\n",
    "    modified_data = process_data(data)\n",
    "    \n",
    "    try:\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as outfile:\n",
    "            json.dump(modified_data, outfile, ensure_ascii=False, indent=4)\n",
    "        print(f\"The modified JSON file has been saved successfully: {output_json_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to save JSON file {output_json_path}: {e}\")\n",
    "\n",
    "\n",
    "input_file = r\"D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_123.json\" \n",
    "output_file = r\"D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_1234.json\"  \n",
    "delete_punctuation_from_json(input_file, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.top 10 word abbreviation to full name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出现频率前十五的全大写单词及出现次数：\n",
      "PM: 4775\n",
      "NBA: 2130\n",
      "BRI: 336\n",
      "VII: 330\n",
      "II: 305\n",
      "NBAGL: 260\n",
      "NBATV: 206\n",
      "EXCEPTION: 167\n",
      "IV: 167\n",
      "ESPN: 160\n",
      "OF: 137\n",
      "VI: 133\n",
      "TNT: 131\n",
      "III: 103\n",
      "SPED: 103\n",
      "CBA: 100\n",
      "ARTICLE: 96\n",
      "FEET: 94\n",
      "TV: 92\n",
      "ROFR: 89\n",
      "出现频率前十五的全大写单词及出现次数：\n",
      "API: 738\n",
      "PCA: 358\n",
      "CV: 282\n",
      "SVC: 256\n",
      "FIX: 194\n",
      "SVM: 185\n",
      "RBF: 163\n",
      "BSD: 133\n",
      "CSR: 129\n",
      "SVR: 105\n",
      "NMF: 100\n",
      "DBSCAN: 95\n",
      "FEATURE: 91\n",
      "ROC: 90\n",
      "SGD: 80\n",
      "OPTICS: 63\n",
      "SVD: 63\n",
      "TRAIN: 63\n",
      "TEST: 63\n",
      "CSC: 60\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def get_top_10_uppercase_words(pdf_path):\n",
    "\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        text = \"\"\n",
    "\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += \" \" + page_text\n",
    "\n",
    "    words = re.split(r'[^A-Za-z0-9]+', text)\n",
    "    \n",
    "\n",
    "    uppercase_words = [w for w in words if len(w) >= 2 and w.isupper() and w.isalpha()]\n",
    "\n",
    "\n",
    "    counter = Counter(uppercase_words)\n",
    "\n",
    "\n",
    "    top_20 = counter.most_common(20)\n",
    "\n",
    "    print(\"The top 20 all-caps words and their frequency:\")\n",
    "    for word, count in top_20:\n",
    "        print(f\"{word}: {count}\")\n",
    "\n",
    "pdf_file_path_NBA =  r'D:\\tsy\\python\\Fidelity\\NBAdoc.pdf'\n",
    "pdf_file_path_SKlearn =  r'D:\\tsy\\python\\Fidelity\\SKlearnPDF.pdf'\n",
    "get_top_10_uppercase_words(pdf_file_path_NBA)\n",
    "get_top_10_uppercase_words(pdf_file_path_SKlearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功保存修改后的JSON文件: D:\\tsy\\python\\Fidelity\\NBA_JSON\\NBA_12345.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "def replace_words_with_explanations(text, word_explanations, case_sensitive=True):\n",
    "\n",
    "\n",
    "    for word, explanation in word_explanations.items():\n",
    "        if case_sensitive:\n",
    "\n",
    "            pattern = r'\\b{}\\b'.format(re.escape(word))\n",
    "        else:\n",
    "\n",
    "            pattern = r'\\b{}\\b'.format(re.escape(word))\n",
    "        \n",
    "\n",
    "        def repl(match):\n",
    "            original_word = match.group(0)\n",
    "            return f\"{original_word} ({explanation})\"\n",
    "        \n",
    "\n",
    "        if case_sensitive:\n",
    "            text = re.sub(pattern, repl, text)\n",
    "        else:\n",
    "            text = re.sub(pattern, repl, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def process_data(data, word_explanations, case_sensitive=True):\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        return {k: process_data(v, word_explanations, case_sensitive) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [process_data(element, word_explanations, case_sensitive) for element in data]\n",
    "    elif isinstance(data, str):\n",
    "        return replace_words_with_explanations(data, word_explanations, case_sensitive)\n",
    "    else:\n",
    "\n",
    "        return data\n",
    "\n",
    "def modify_json_words_nba(input_json_path, output_json_path, word_explanations, case_sensitive=True):\n",
    "\n",
    "    try:\n",
    "        with open(input_json_path, 'r', encoding='utf-8') as infile:\n",
    "            data = json.load(infile)\n",
    "    except Exception as e:\n",
    "        print(f\"unable to read JSON file {input_json_path}: {e}\")\n",
    "        return\n",
    "    \n",
    "    modified_data = process_data(data, word_explanations, case_sensitive)\n",
    "    \n",
    "    try:\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as outfile:\n",
    "            json.dump(modified_data, outfile, ensure_ascii=False, indent=4)\n",
    "        print(f\"The modified JSON file has been saved successfully: {output_json_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to save JSON file {output_json_path}: {e}\")\n",
    "\n",
    "\n",
    "word_explanations = {\n",
    "  \"NBA\": \"National Basketball Association\",\n",
    "  \"BRI\": \"Basketball Related Income\",\n",
    "  \"NBAGL\": \"National Basketball Association G League\",\n",
    "  \"NBATV\": \"National Basketball Association Television\",\n",
    "  \"ESPN\": \"Entertainment and Sports Programming Network\",\n",
    "  \"TNT\": \"Turner Network Television\",\n",
    "  \"SPED\": \"Special Events Department\",\n",
    "  \"CBA\": \"Collective Bargaining Agreement\",\n",
    "  \"TV\": \"Television\",\n",
    "  \"ROFR\": \"Right of First Refusal\"\n",
    "}\n",
    "input_file = r\"D:\\tsy\\python\\Fidelity\\NBA_JSON\\NBA_1234.json\"           \n",
    "output_file = r\"D:\\tsy\\python\\Fidelity\\NBA_JSON\\NBA_12345.json\" \n",
    "case_sensitive = True \n",
    "modify_json_words_nba(input_file, output_file, word_explanations, case_sensitive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 for sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功保存修改后的JSON文件: D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_12345.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "def replace_words_with_explanations(text, word_explanations, case_sensitive=True):\n",
    "\n",
    "    for word, explanation in word_explanations.items():\n",
    "        if case_sensitive:\n",
    "\n",
    "            pattern = r'\\b{}\\b'.format(re.escape(word))\n",
    "        else:\n",
    "\n",
    "            pattern = r'\\b{}\\b'.format(re.escape(word))\n",
    "        \n",
    "\n",
    "        def repl(match):\n",
    "            original_word = match.group(0)\n",
    "            return f\"{original_word} ({explanation})\"\n",
    "        \n",
    "\n",
    "        if case_sensitive:\n",
    "            text = re.sub(pattern, repl, text)\n",
    "        else:\n",
    "            text = re.sub(pattern, repl, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def process_data(data, word_explanations, case_sensitive=True):\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        return {k: process_data(v, word_explanations, case_sensitive) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [process_data(element, word_explanations, case_sensitive) for element in data]\n",
    "    elif isinstance(data, str):\n",
    "        return replace_words_with_explanations(data, word_explanations, case_sensitive)\n",
    "    else:\n",
    "\n",
    "        return data\n",
    "\n",
    "def modify_json_words_sklearn(input_json_path, output_json_path, word_explanations, case_sensitive=True):\n",
    "\n",
    "    try:\n",
    "        with open(input_json_path, 'r', encoding='utf-8') as infile:\n",
    "            data = json.load(infile)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to read the JSON file {input_json_path}: {e}\")\n",
    "        return\n",
    "    \n",
    "\n",
    "    modified_data = process_data(data, word_explanations, case_sensitive)\n",
    "    \n",
    "    try:\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as outfile:\n",
    "            json.dump(modified_data, outfile, ensure_ascii=False, indent=4)\n",
    "        print(f\"The modified JSON file has been saved successfully: {output_json_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to save JSON file {output_json_path}: {e}\")\n",
    "\n",
    "\n",
    "word_explanations = {\n",
    "  \"API\": \"Application Programming Interface\",\n",
    "  \"PCA\": \"Principal Component Analysis\",\n",
    "  \"CV\": \"Cross-Validation\",\n",
    "  \"SVC\": \"Support Vector Classification\",\n",
    "  \"SVM\": \"Support Vector Machine\",\n",
    "  \"RBF\": \"Radial Basis Function\",\n",
    "  \"BSD\": \"Binary Search Decision\",\n",
    "  \"CSR\": \"Compressed Sparse Row\",\n",
    "  \"SVR\": \"Support Vector Regression\",\n",
    "  \"NMF\": \"Non-Negative Matrix Factorization\"\n",
    "}\n",
    "input_file = r\"D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_1234.json\"           \n",
    "output_file = r\"D:\\tsy\\python\\Fidelity\\SKLearn_JSON\\sklearn_12345.json\" \n",
    "case_sensitive = True \n",
    "modify_json_words_sklearn(input_file, output_file, word_explanations, case_sensitive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功保存修改后的JSON文件: D:\\tsy\\python\\Fidelity\\NBA_JSON\\NBA_5.json\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 125\u001b[0m\n\u001b[0;32m    121\u001b[0m         apply_functions_sequentially(input_json_path, output_json_path, function_list)\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m所有函数组合已完成处理。\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 125\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 121\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    118\u001b[0m     output_json_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, output_filename)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# 应用函数组合到原始数据\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     \u001b[43mapply_functions_sequentially\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_json_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_json_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m所有函数组合已完成处理。\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 66\u001b[0m, in \u001b[0;36mapply_functions_sequentially\u001b[1;34m(input_path, output_path, functions)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# 最后一个函数的输出是最终输出文件\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     final_func \u001b[38;5;241m=\u001b[39m functions[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 66\u001b[0m     \u001b[43mfinal_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_explanations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# 清理临时文件\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m temp_path \u001b[38;5;129;01min\u001b[39;00m temp_files:\n",
      "Cell \u001b[1;32mIn[5], line 47\u001b[0m, in \u001b[0;36mprocess_json_file\u001b[1;34m(input_json_path, output_json_path, probability)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 47\u001b[0m         modified_value \u001b[38;5;241m=\u001b[39m \u001b[43mmodify_letters_with_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobability\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m         data[key] \u001b[38;5;241m=\u001b[39m modified_value\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m, in \u001b[0;36mmodify_letters_with_probability\u001b[1;34m(text, probability)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m text:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m char\u001b[38;5;241m.\u001b[39misalpha():\n\u001b[1;32m---> 17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprobability\u001b[49m:\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;66;03m# 根据字符的大小写选择替换范围\u001b[39;00m\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m char\u001b[38;5;241m.\u001b[39mislower():\n\u001b[0;32m     20\u001b[0m                 replacement \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(string\u001b[38;5;241m.\u001b[39mascii_lowercase)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'dict'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "\n",
    "word_explanations = {\n",
    "  \"NBA\": \"National Basketball Association\",\n",
    "  \"BRI\": \"Basketball Related Income\",\n",
    "  \"NBAGL\": \"National Basketball Association G League\",\n",
    "  \"NBATV\": \"National Basketball Association Television\",\n",
    "  \"ESPN\": \"Entertainment and Sports Programming Network\",\n",
    "  \"TNT\": \"Turner Network Television\",\n",
    "  \"SPED\": \"Special Events Department\",\n",
    "  \"CBA\": \"Collective Bargaining Agreement\",\n",
    "  \"TV\": \"Television\",\n",
    "  \"ROFR\": \"Right of First Refusal\"\n",
    "}\n",
    "\n",
    "function_mapping = {\n",
    "    1: process_json_file,\n",
    "    2: convert_json_file_to_uppercase,\n",
    "    3: modify_json_spaces,\n",
    "    4: delete_punctuation_from_json,\n",
    "    5: modify_json_words_nba(input_file, output_file, word_explanations, case_sensitive)\n",
    "}\n",
    "\n",
    "def get_all_non_empty_combinations(functions):\n",
    "\n",
    "    all_combinations = []\n",
    "    for r in range(1, len(functions)+1):\n",
    "        combinations_r = list(itertools.combinations(functions, r))\n",
    "        all_combinations.extend(combinations_r)\n",
    "    return all_combinations\n",
    "\n",
    "def apply_functions_sequentially(input_path, output_path, functions):\n",
    "\n",
    "    current_input = input_path\n",
    "    temp_files = []\n",
    "    \n",
    "    try:\n",
    "        for func in functions[:-1]:\n",
    "\n",
    "            temp_fd, temp_path = tempfile.mkstemp(suffix=\".json\")\n",
    "            os.close(temp_fd)  \n",
    "            temp_files.append(temp_path)\n",
    "            \n",
    "\n",
    "            func(current_input, temp_path, word_explanations)\n",
    "            \n",
    "\n",
    "            current_input = temp_path\n",
    "\n",
    "        final_func = functions[-1]\n",
    "        final_func(current_input, output_path, word_explanations)\n",
    "        \n",
    "    finally:\n",
    "\n",
    "        for temp_path in temp_files:\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "\n",
    "def generate_output_filename(original_filename, function_numbers):\n",
    "\n",
    "    base, ext = os.path.splitext(original_filename)\n",
    "    sorted_numbers = ''.join(map(str, sorted(function_numbers)))\n",
    "    return f\"{base}_{sorted_numbers}{ext}\"\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    functions = [\n",
    "        (1, function_mapping[1]),\n",
    "        (2, function_mapping[2]),\n",
    "        (3, function_mapping[3]),\n",
    "        (4, function_mapping[4]),\n",
    "        (5, function_mapping[5]),\n",
    "    ]\n",
    "    \n",
    "\n",
    "    function_combinations = get_all_non_empty_combinations(functions)\n",
    "    \n",
    "\n",
    "    input_json_path = r\"D:\\tsy\\python\\Fidelity\\NBA.json\"  \n",
    "    output_folder = r\"D:\\tsy\\python\\Fidelity\\NBA_json\"  \n",
    "    \n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    original_filename = os.path.basename(input_json_path)\n",
    "    \n",
    "\n",
    "    for combo in function_combinations:\n",
    "\n",
    "        function_numbers = [func[0] for func in combo]\n",
    "        function_list = [func[1] for func in combo]\n",
    "        \n",
    "\n",
    "        output_filename = generate_output_filename(original_filename, function_numbers)\n",
    "        output_json_path = os.path.join(output_folder, output_filename)\n",
    "        \n",
    "        \n",
    "        apply_functions_sequentially(input_json_path, output_json_path, function_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_1.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_12.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_123.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_1234.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_12345.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_1235.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_124.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_1245.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_125.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_13.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_134.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_1345.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_135.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_14.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_145.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_15.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_2.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_23.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_234.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_2345.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_235.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_24.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_245.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_25.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_3.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_34.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_345.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_35.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_4.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_45.pdf\n",
      "PDF 文件已成功保存为 D:\\tsy\\python\\Fidelity\\NBAPDF\\NBA_5.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.platypus import Paragraph, Frame\n",
    "from reportlab.platypus import Preformatted\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "\n",
    "def json_to_pdf_reportlab(json_path, pdf_path, font_path=None, font_size = 6):\n",
    "    \n",
    "    c = canvas.Canvas(pdf_path, pagesize=A4)\n",
    "    width, height = A4\n",
    "\n",
    "    \n",
    "    with open(json_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    sorted_pages = sorted(data.keys(), key=lambda x: int(x))\n",
    "\n",
    "    styles = getSampleStyleSheet()\n",
    "    custom_style = ParagraphStyle(\n",
    "        'CustomStyle',\n",
    "        parent=styles['Normal'],\n",
    "        fontName='Helvetica',  \n",
    "        fontSize=font_size,\n",
    "        leading=font_size * 1.2,  \n",
    "    )\n",
    "\n",
    "\n",
    "    for page_num in sorted_pages:\n",
    "        content = data[page_num]\n",
    "        if font_path:\n",
    "            from reportlab.pdfbase import ttfonts, pdfmetrics\n",
    "            pdfmetrics.registerFont(ttfonts.TTFont('CustomFont', font_path))\n",
    "            custom_style.fontName = 'CustomFont'\n",
    "\n",
    "        frame = Frame(0, 0, width-100, height-100, showBoundary=0)\n",
    "        para = Preformatted(content, custom_style)\n",
    "        frame.addFromList([para], c)\n",
    "        c.showPage()\n",
    "\n",
    "    c.save()\n",
    "    print(f\"The PDF file has been successfully saved as {pdf_path}\")\n",
    "\n",
    "def batch_convert_json_to_pdf(input_dir, output_dir, font_path=None, font_size=6):\n",
    "\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Create output folder: {output_dir}\")\n",
    "\n",
    "    \n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith('.json'):\n",
    "            json_file_path = os.path.join(input_dir, filename)\n",
    "            pdf_filename = os.path.splitext(filename)[0] + '.pdf'\n",
    "            pdf_file_path = os.path.join(output_dir, pdf_filename)\n",
    "\n",
    "            \n",
    "            json_to_pdf_reportlab(json_file_path, pdf_file_path, font_path, font_size)\n",
    "\n",
    "input_dir = r\"D:\\tsy\\python\\Fidelity\\NBA_JSON\"\n",
    "output_dir = r\"D:\\tsy\\python\\Fidelity\\NBAPDF\"\n",
    "font_file = r\"D:\\tsy\\python\\Fidelity\\DejaVuSans.ttf\"\n",
    "batch_convert_json_to_pdf(input_dir, output_dir, font_path=font_file, font_size=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
